<!doctype html>
<html>

<head>
	<meta charset="utf-8" />
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<script defer src="/project/portfolio.js">
	</script>
	<title>Understanding User Interactions</title>

	<link rel="stylesheet" href="/project/portfolio.css" />

</head>

<body>

 <!--hamburger nav-->
<nav aria-labelledby="hamburger">
  <button id="hamburger" class="hamburger" aria-label="Show Navigation Menu" aria-expanded="false" tabindex="0">☰</button>

  <div id="navMenu" class="navMenu hidden vh">
    <button id="closeNavMenu" class="closeBtn" aria-label="Hide Navigation Menu">×</button>
    <ul>
      <li><a href="/index.html">Portfolio</a></li>
      <li><a href="/about/about.html">About</a></li>
      <li><a href="/art/art.html">Art</a></li>
      <li><a href="/contact/contact.html">Contact</a></li>
    </ul>
  </div>
</nav>
<!--hamburger nav ends-->

  <main>

<div class="centerthetext">
<h2>Human-Human Interaction in Web-Based VR </h2>
</div>

<div class="centerthetext">
<h3 class="titlecenter">A study on collaborative interaction on Mozilla Hubs </h3>
</div>

    
<div class="centerthetext">
<div class="flex-container1-text">
 <div class="row">
  <div class="column">
<p class="blogtext">
The aim of this study is to investigate how people with no experience in Web-Based Virtual Reality interact, communicate, collaborate, and socialise with others on Mozilla Hubs after registering with the platform and creating chat rooms. Mozilla Hubs is an open-source project which provides VR chat rooms for its users. This platform was chosen considering the momentum that the extended reality applications have gained recently, especially during the pandemic since such technology offers much more realistic and engaging means of communication. The study focuses on both the communication and social aspects of the browser-based VR experience on Mozilla Hubs since both aspects are viewed as being entwined.
</p>
  </div>
 </div>
</div>
</div>
<br>
<br>

<div class="centerthetext">
<h3 class="titlecenter">Theory Selection and Planning</h3>
</div>
    
<div class="centerthetext">
<div class="flex-container1-text">
 <div class="row">
  <div class="column">
<p class="blogtext">  
The observations involving participant-chosen realistic tasks were planned to take place in their natural environment. Participants would set their tasks which they could realistically perform “according to how they wanted to use the space, if they were to use Mozilla Hubs as an alternative to the communication platforms they regularly use”.
<br>
<br>
An ethics checklist was completed as the first planning action.
The technique to be used was naturalistic observation, yet it was still necessary to plan what to focus on. The amount of information without having a focus would have been overwhelming. Therefore, a plan was made on what to learn, what questions needed answers, how the information would be gathered, and what could be ignored or discarded.
<br>
<br>
Three participants were recruited for the study. All participants are long-term daily users of the internet, especially social media and communication platforms such as Instagram, Facebook, WhatsApp, Zoom and Microsoft Teams. Although all of them had heard about Virtual Reality in games context, none of them had experience of using it for social interaction and collaboration, nor had they experience with anything similar in a browser-based environment. One participant had experience in 3D modelling and games.
<br>
<br>
   The participants were given printed copies of the ‘participant information sheets’ as well as ‘consent forms’ in person, which they signed and returned.
<br>
<br>
A short pilot study was conducted to ensure the use of the most suitable frameworks as well as getting familiar with observation on Mozilla Hubs. Due to the restrictions of the pandemic, a short pilot test was conducted fully online even though the study would involve observing participants also in their natural environment. This was appropriate since the main goal of the pilot test was to evaluate the effectiveness of observing in VR, any preparation that needed to be done and the technical aspects that needed to be considered. During this test, VR observation, which was a possibility until then, was confirmed as a method to be applied, making the pilot test a very important phase of the study.
<br>
<br>
     Both ‘think aloud’ and ‘think after’ were considered as possible techniques since the study also had an individual observation phase; firstly, the emphasis was on ‘think after’ due to its being less intrusive and allowing more natural task completion. However, it was decided that it wouldn’t be suitable since it could have easily been influenced by forgetting and fabrication (Branch, 2000) in an environment where the participants were being exposed to a lot of information. On the other hand, ‘think aloud’ was considered optional in the first part of the study since it would be short, while the group setting would bear most of the important tasks.
<br>
<br>
<br>
<strong>Data Collection</strong>
<br>
<br>
   As described by Rodwell “It is in the doing of data collection that the understanding of the subject of interest is achieved”.
<br>
<br>
In this study, data collection was designed to consider context and anything that might or might not occur in that context without the intervention of the facilitator. As a result of this ‘context-dependency’, there were no strict guidelines for data collection, but the most appropriate collection actions would be performed as required. The study was designed in a way that allowed both individual and group observation. It started with 3 participants’ signing up with the platform individually and each of them creating a VR room, then it continued as a group once the brief individual observations were complete and all participants gathered in P1’s VR room, followed by the others’.
<br>
<br>
     The participants were observed in their natural environment, in their living room with a couple of meters of distance between them, using laptops (1x Macbook Pro and 2x Windows laptops) wearing headphones and using a microphone. It was possible to observe both the participants in person from a similar distance and their screen at the same time by joining the VR rooms of each participant and seeing all three of them performing their mutually agreed tasks. The participants used “think-aloud” in the individual tasks while the group tasks were naturally in the form of informal group chat and discussions. Screen recordings of each participant had been planned as a data collection medium, however, in the pilot test, it was clear that it would be easier to observe the participants also in the virtual room while I was invisible to them. Therefore, I decided to record only my screen with audio where I could observe their actions and take screenshots of their chat windows. In addition, relevant notes were taken during the session.
<br>
<br>
     The data collection process was very thorough due to the nature of the chosen VR environment and the presence of the participants in the room. It was possible to observe the way the participants interacted with the platform in person, as well as their movements and actions in the virtual environment via their avatars while they were naturally performing collaborative think-aloud.
<br>
<br>
<br>
<strong>Data Analysis</strong>
<br>
<br>
The observations led to rich raw data in the form of written notes based on the observation of the participants in person in a physical space, including their gestures, facial expressions, interaction with each other and the platform, ie. how they used the keyboard and the mouse, which was critical in the navigation of the virtual space. In addition, I had notes on the initial stage of the ‘sign-up’ process of each participant. I decided not to record this part because I did not want to have a record of their personal login information but also it was a very straightforward task of only entering an email, which returned a confirmation email to their mailbox to confirm the registration. I also had a screen recording of three different virtual rooms, created by each participant, who then invited the others by posting the room link in the ‘Chat box’. These were recorded on my own laptop while all three participants performed the tasks and actions, and I was an ‘invisible’ observer during all the tasks including moving from one room to another with them, which is a feature that the platform provided.
<br>
<br>
I watched the screen recordings again to make sure I had not missed anything in the virtual spaces, which helped me to familiarise myself with the data and take further notes of direct quotes from the participants. The data was turned into valuable insights by using Situated Action and DiCoT, which provided a structure for analysis.
<br>
<br>
  
<strong>Findings</strong>
<br>
While it is not possible to include all findings considering the scope and limits of the study, the focus was on presenting the most significant ones, followed by design guidelines to address them.
</p>
  </div>
 </div>
</div>
</div>

<div style="align: left; text-align:center;">
<img src="/project/img/uuitable.jpeg" alt="user journey table" style="width:80%" class="center" onContextMenu="return false;" draggable="false">
</div>

    

<div class="centerthetext">
<div class="flex-container1-text">
 <div class="row">
  <div class="column">
<p class="blogtext">
As seen on the table above, the individual tasks, which each user was observed performing one-by-one so that they wouldn’t observe each other’s screens, were straightforward and all the steps were required to be able to reach the goal of signing up and creating a room. While the participants were initially confused since there was no “sign-up”, but only “sign in” option, they spent a couple of to a few minutes on the page looking for the right button, then all clicked “Sign In” to see what would happen, which prompted them to enter an email address without any other details. This was an unconventional way of signing up for all participants whose confused expressions confirmed this, yet they completed the tasks with success and when they were asked how they had found the experience, before moving to the group, they said that they preferred to sign in like that rather than entering a lot of details.
<br>
<br>
The second part of the individual task was creating a room, which was also straightforward as soon as they signed in. After all participants signed in, they decided to copy their room links by clicking “Invite” (preparing for future action) and share it with each other via a group chat on FB Messenger on a separate tab. They posted their links and decided to visit the room of P1 first. There, they noticed that there is a ‘Chat’ in the room which they could use to post links, so they abandoned FB (revising plan).
<br>
<br>
There were positive findings which the users expressed verbally such as the quick sign-up process and VR room creation, engaging environment, and the use of avatars. They stated that it was more interactive and enjoyable compared to other platforms like Zoom. While the interface loaded, which took a few minutes; on the screen, a few tips on navigation were present, one of which told the user to move to left and right with “Q and E keys”, which was missed by two of the participants as they were not paying attention while it was loading, and they had not expected to find tips on a loading screen.
<br>
<br>
The tasks performed included placing 3D objects directly from the platform or uploading from their computer, exploring the objects that were already in the room, removing objects, using the chat function, screen share and live video functions. All these tasks were unique to Mozilla Hubs and were different from their previous experience of using communication platforms. By adapting to the situation they were in, the participants designed and performed their own tasks to achieve similar goals they would have on the other platforms.
<br>
<br>
<br>
<strong>DiCoT</strong>
<br>
<br>
   The most critical findings were in the group setting, around the difficulty of the findability of the room functions and lack of resilience considerations. Group tasks were flexible, and the participants were free to perform their chosen tasks in the order they preferred. Firstly, they explored the interface (room) by navigating with the arrow keys, very similar to how it would work in gaming but different from how communication platforms work. P1 was very confident (she regularly played games) while P2 and P3 needed more time to get used to it.
<br>
<br>
   The three types of models below, based on DiCoT, were chosen to address the core issues. These models are physical model, information flow model, and the social model.
<br>
<br>
<br>
 <strong>Physical Model</strong>
<br>
<br>
   The physical model refers to the factors that might have influenced the usage of the platform, and of components of the platform, at a physical level. The physical model aspect is important to talk about from a distributed cognition perspective; what the users can physically see and hear will have a direct impact on their cognitive space and therefore will shape their behaviours, eg. encourage or limit them in their performance. During the observation, the users were in their living room, however with a couple of meters of distance from each other, without seeing each other’s screens. Although they were not in close proximity, this was still a concern in the beginning on the researcher’s side; it was thought that they could get distracted by each other or would not engage fully in the virtual communication activities when they were physically in the same room.
<br>
<br>
   It was observed that, they were conscious of each other and were trying to figure out by looking around if the other participants were ahead of them, especially when one participant seemed to enjoy the experience by laughing and verbally expressing their enjoyment. However, a change was observed after some time. As the participants started getting used to the virtual space, they were moving away from the physical space and were not being distracted by each other’s movements and verbal reactions compared to the time when they started exploring the platform and were not very confident about using it. Later, the (negative) effect of the physical space was observed to fade as they were getting immersed in their virtual space and actions after some time and experience with the platform. This was an interesting find in the observation; it almost looked like their physical environment was becoming the virtual room instead of the living room they were in.
<br>
<br>
<br>
<strong>Information Flow Model</strong>
<br>
<br>
   Mozilla Hubs allowed the participants to collaborate in all the tasks with varying levels of focus and understanding. The communication between the participants, their roles, the order of events and tasks could all be included in the information flow model. The interface had a ‘Chat’ function which the users made use of to send each other the links for room invites as well as directions on how to perform certain tasks such as moving and resizing objects, which required multiple steps to reach the goal. Despite the richness and complexity of some of the tasks performed, it was interesting that the participants did not attempt to seek any external support for the flow of information, this was thought to be due to the nature of the VR environment they were in, where they were present with their avatars (representations), similar to being in a room in the physical world. The information flow was mainly within the platform (the VR rooms) by using the chat, and informal verbal communication. In this case, they were in the same room, so would be able to hear each other in the physical space, however, they still used microphone and headphones, like how they would communicate in the other platforms.
<br>
<br>
   As it is mentioned below in the Social Model, one of the participants took the lead role and was influential in the information flow, as well as the understanding of the tasks and cognition.
<br>
<br>
<br>
<strong>Social Model</strong>
<br>
<br>
   After the initial difficulties with the platform and one of the participants’ supporting the others to perform certain tasks by talking them through and using the chat function, that participant took on the leader role. She would make suggestions such as “why don’t you screenshare and show us that video?”, or “Can you click that to add the pdf to the room?”. This was the younger participant in the group who also had never used the platform while she was experienced in games and 3D modelling, which made the environment feel more familiar to her compared to the others who normally used the internet daily for communication, work, as well as reading and watching various content. It was very clear that the previous experience of the younger user gave her the power to lead, which was accepted and appreciated by the other participants. However, this also meant that the other two participants would have struggled more with task setting and performing if there had been only two of them present in the study. This shows how important it is to recruit participants with diverse backgrounds and design carefully selected participant groups. In the future, without restrictions such as the current pandemic, I would aim to form participant groups with even more varied demographics. It is very likely that there would be more findings to talk about within especially the social model aspect.
<br>
<br>
<br>
<strong>Design Guidelines</strong>
<br>
<br>
This section details some of the issues mentioned in the findings and offers recommendations towards evolutionary changes.
<br>
<br>
<strong>  Design for Every User</strong>
<br>
<br>
   Even though Mozilla Hubs is a young platform, it is important to acknowledge that it is growing and there will be diverse types of users on the platform parallel to its growth. In this study, all participants were experienced in using the internet, social media and communication software, they found the experience relatively comfortable, however there were moments when they could not easily figure out how to perform certain actions. They expected the signifiers for actions to be more visible on the screen. For example, it took a while until the ‘lead participant’ discovered how to select, move, and resize the objects and it was a discovery of trial and error. They did not choose to search on the web, which might have been due to being in a more ‘confined’ virtual space.
<br>
<br>
   To tackle similar issues, the user can be provided with more information, ideally interactive tips about how to use the interface, especially, how to move around and perform certain tasks. These could be provided as a “help bar” on the corner of the page without interrupting the experience, similar to how the “objects” are placed in a drop-down menu on the interface. Then the user can refer to it whenever they need assistance. Alternatively, with the current technology in mind, it could be possible to design a ‘virtual assistant’ in the rooms which the users could activate/deactivate as needed and interact with via both voice and text (similar to applications such as Apple’s Siri or Google Assistant). The fact that none of the participants performed a text-based search brought up the idea that the users would benefit from an internal interactive medium, rather than leaving the page to search for information externally. To implement changes, testing the platform with users from different backgrounds would benefit both the platform and the users in the long term.
<br>
<br>
   As Whitenton suggested, “Users must bridge the gulfs of evaluation and execution to successfully interact... but the challenge becomes much easier when [designers] are aware of these gulfs, and build in cues to send users down the right path.” (2018). This could apply to both this guideline, and the next guideline ‘designing for resilience’.
<br>
<br>
<strong>Design for Resilience</strong>
<br>
<br>
   Designing for the user should also mean designing for resilience. It is important to understand what resilience means in this context. It can be defined as being ready for unexpected and uncertain states of the system or product in use, it should allow adaptation and recovery.
<br>
<br>
   Mozilla Hubs is a constantly evolving project, and it would be correct to say that they listen to their users and make adaptations; however, there are still important core features that could have already been reviewed and redesigned, which would make significant changes in the general user experience. One of these is the Chat function, which cannot be saved or recovered should a user need to leave the room temporarily, which was experienced during the observation when one of the participants’ screen became unresponsive and they had to refresh their browser. When they came back, they lost some key information that was in the chat and had to ask for it again, while by that time, the other two participants had moved on to other tasks. This can be especially problematic when the chat room has more participants. These rooms can host up to 50 people and in the busier situations, there would be more reliance on the chat function if it is a meeting with only a few speakers and the rest being the audience. Users may want to ask questions via the chat without disrupting the speaker or they might feel more comfortable with writing rather than talking. If the general internet or browser issues are considered, as well as physical disruptions that might cause the user to leave temporarily, a ‘save’, or even better, an ‘auto-save’ function provided for the whole room, allowing it to be downloaded at the end of the session would be very useful so that the users can access the content they might have missed in the chat window during an interruption.
<br>
<br>
Another issue was resizing the objects in the room when the participants uploaded their own. In two different occasions, the resize function did not work well, was unstable causing the objects to be scaled up to such a large size that they became unresponsive on one occasion, and on another, the original uploaded 3d model was too large and it was impossible to resize it. On both occasions, the uploaded models had to be deleted and re-uploaded several times while they tried to resize it each time. This caused the participants to give up and use 3D objects from the Hubs’ portfolio. This issue was not major in this study, however, if the uploaded objects had had critical importance in their communication and collaboration, it would have been a failure with higher severity rating.
<br>
<br>
<br>
<strong>Evaluation of the Chosen Theoretical Frameworks</strong>
<br>
<br>
<strong>DiCoT</strong>
<br>
<br>
   DiCoT provided the very much needed structure, and it was the most appropriate framework to analyse the data gathered from multiple users in a social and collaborative environment. Being in the same space both in the physical and virtual rooms with the participants provided a rich base for this framework to be applied, allowing the analysis of physical and social behaviours in both a physical and a virtual setting.
<br>
<br>
<strong>Situated Action</strong>
<br>
<br>
   SA clearly fit this study in that the participants experienced a new environment that led to situation-based planning; even though the tasks they performed might have been their daily tasks in other environments, the way they chose or had to perform those in Mozilla Hubs was influenced by the new situation they found themselves in. They might have had certain mental models about the actions influenced by their previous experience, however, they did not have the plans for the actions.
<br>
   Both frameworks led to an insightful analysis of the data; the only concern would be the low number of participants. If there had been participants with more varied backgrounds in terms of especially experience with the internet and other software, there would possibly be more insight and guidelines to propose.
<br>
<br>
<em>*P1: Participant 1, P2: Participant 2, P3: Participant 3</em>
<br>
<br>
<br>
<br>

<strong>REFERENCES</strong>
<br>
<br>
Blandford,  A. & Furniss, D. (2005)  DiCoT: A  methodology for applying Distributed Cognition to the design of team working systems. Proc. DSVIS 2005. Springer: LNCS.
<br>
<br>
DePoy, E. and N., L., 2015. Introduction to Research. Elsevier.
Erlandson D, Harris E, Skipper B, Allen S. Doing Naturalistic Inquiry: A Guide to Methods. Newbury Park: Sage; 1993
<br>
<br>
Furniss, D., Blandford, A. and Curzon, P., (2007). 'Resilience in Usability Consultancy Practice: the case for a positive resonance model', Linköping Electronic Conference Proceedings. Vadstena, Sweden, 25–27 June 2007. Sweden: Linköping University Electronic Press.
<br>
<br>
Hartson, R. and S., P., 2018. The UX Book. Elsevier Science.
<br>
<br>
Hind Kharoub, Mohammed Lataifeh, Naveed Ahmed (2019) '3D User Interface Design and Usability for Immersive VR', Applied Sciences, 9(22).
<br>
<br>
K., M. and Katherine, M., 1998. Social Work, Constructivist Research. Taylor & Francis.
<br>
<br>
Kirsh, D, 2010. 'Thinking with external representations', AI & Society, (25), pp. 441-454.
<br>
<br>
Makri, S., 2010. 'This is what I’m doing and why: Methodological reflections on a naturalistic think-aloud study of interactive information behaviour', Information Processing & Management, vol. 47, no. 3, pp. 336-348.
<br>
<br>
Seabra, M., 2007. A Portrait of State-of-the-Art Research at the Technical University of Lisbon. Springer Science & Business Media.
<br>
<br>
The Mozilla Blog. 2018. Enabling Social Experiences Using Mixed Reality and the Open Web - The Mozilla Blog. [ONLINE] Available at: https://blog.mozilla.org/blog/2018/04/26/enabling-social-experiences-using-mixed-reality-and-the-open-web/. [Accessed 29 March 2021].

</p>
  </div>
 </div>
</div>
</div>


  </main>

</body>

</html>

